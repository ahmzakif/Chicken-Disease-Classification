{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VGG16 model\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import Image\n",
    "\n",
    "# Open file\n",
    "import os\n",
    "import PIL\n",
    "\n",
    "# Model CNN (Deep learning network)\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense,\\\n",
    "GlobalAveragePooling2D, Dropout, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# set default random state \n",
    "from random import seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function plot loss function and accuracy score graph\n",
    "def plot_graph(model_values):\n",
    "    ''' \n",
    "    Input : Model_values of keras.callbacks.History\n",
    "    Return : Graph of Loss function and accuracy score between training dataset and vaildation dataset\n",
    "    '''\n",
    "    # Subplots\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(14,5))\n",
    "    \n",
    "    # Plot loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(model_values.history['loss'], label='Training Loss');\n",
    "    plt.plot(model_values.history['val_loss'], label='Testing Loss');\n",
    "    plt.legend(fontsize=12, loc='upper right')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss');\n",
    "    \n",
    "    # Plot MSE\n",
    "    plt.subplot(1, 2, 2)\n",
    "    \n",
    "    plt.plot(model_values.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(model_values.history['val_accuracy'], label='Validation Accuracy')\n",
    "    \n",
    "    plt.legend(fontsize=12, loc='lower right')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "00. Check GPU\n",
    "   ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 16509579719280035336\n",
      "xla_global_id: -1\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "01. Open Datasets\n",
    "   ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open path file of dataset \n",
    "seed(42)\n",
    "dataset_path_new = \"dataset_train_valid_test\"\n",
    "\n",
    "train_dir = os.path.join(dataset_path_new, \"train\")\n",
    "valid_dir = os.path.join(dataset_path_new, \"valid\")\n",
    "test_dir = os.path.join(dataset_path_new, \"test\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "02. Preprocessing Image Datasets\n",
    "   ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameter of image \n",
    "# The default input size for this VGG16 model is 224x224\n",
    "# https://keras.io/api/applications/vgg/\n",
    "batch_size = 50 # Set the batch size for epoch cycle\n",
    "img_height = 224 # Set the height of the picture\n",
    "img_width = 224 # Set the width of the picture\n",
    "\n",
    "# Rescale pixel to reduce image size before using in model\n",
    "data_gen_train = ImageDataGenerator(rescale=1/255.)\n",
    "data_gen_valid = ImageDataGenerator(rescale=1/255.)\n",
    "data_gen_test = ImageDataGenerator(rescale=1/255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7758 images belonging to 4 classes.\n",
      "Found 834 images belonging to 4 classes.\n",
      "Found 813 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "# Create training dataset \n",
    "train_dataset = data_gen_train.flow_from_directory(train_dir,\n",
    "                                                   class_mode=\"categorical\",\n",
    "                                                   target_size=(img_height, img_width),\n",
    "                                                   batch_size=batch_size)\n",
    " \n",
    "\n",
    "# Create validation dataset \n",
    "valid_dataset = data_gen_valid.flow_from_directory(valid_dir,\n",
    "                                                   class_mode=\"categorical\",\n",
    "                                                   target_size=(img_height, img_width),\n",
    "                                                   batch_size=batch_size)\n",
    "\n",
    "# Create testing dataset \n",
    "test_dataset = data_gen_test.flow_from_directory(test_dir,\n",
    "                                                   class_mode=\"categorical\",\n",
    "                                                   target_size=(img_height, img_width),\n",
    "                                                   batch_size=batch_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "03. VGG16 Model Training\n",
    "   ---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import vgg16 model form keras API\n",
    "# set input size of image of trianing is 224x224\n",
    "# due to we want to use transfer learning process \n",
    "# we must add `include_top=False` because we wan to add our input data \n",
    "# we decide default weigh for model \n",
    "vgg16_model = tf.keras.applications.VGG16(input_shape=(224,224,3),\n",
    "                                          include_top=False, # Transfer learning\n",
    "                                          weights=\"imagenet\",\n",
    "                                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14714688 (56.13 MB)\n",
      "Trainable params: 14714688 (56.13 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model summary\n",
    "vgg16_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix weights and bias in hidden layers\n",
    "# train specifically custom head and output layer\n",
    "vgg16_model.trainable=False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add custom head and output layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output layer \n",
    "# We have 4 classes in our output we decide using activation=\"softmax\" \n",
    "# for multi classification.\n",
    "# Before output layer we decide use GlobalAveragePooling2D as \n",
    "# one type of flatten layer.\n",
    "average_pooling_layer = tf.keras.layers.GlobalAveragePooling2D()(vgg16_model.output) # flatten\n",
    "prediction_layer = tf.keras.layers.Dense(units=4, activation=\"softmax\")(average_pooling_layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Input layer and output layer \n",
    "model = tf.keras.models.Model(inputs=vgg16_model.input, \n",
    "                                    outputs=prediction_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model         \n",
    "model.compile(loss=\"categorical_crossentropy\", \n",
    "              optimizer = tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " global_average_pooling2d (  (None, 512)               0         \n",
      " GlobalAveragePooling2D)                                         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4)                 2052      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14716740 (56.14 MB)\n",
      "Trainable params: 2052 (8.02 KB)\n",
      "Non-trainable params: 14714688 (56.13 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# check model summary\n",
    "# total params: 14,716,740 (hidden layers)\n",
    "# trainable params: 2,052 (input and output layers)\n",
    "model.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save checkpoints during training\n",
    "checkpoint_path = \"model/vgg16/training_vgg16_cp/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training model\n",
    "# make sure you truely save checkpoint_path\n",
    "history = model.fit(train_dataset,\n",
    "          epochs=25,\n",
    "          validation_data=valid_dataset,\n",
    "          callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot graph \n",
    "plot_graph(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the history.history dict to a pandas DataFrame:     \n",
    "hist_df = pd.DataFrame(history.history) \n",
    "hist_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save history to csv: \n",
    "hist_csv_file = 'model/vgg16/history_vgg16.csv'\n",
    "with open(hist_csv_file, mode='w') as f:\n",
    "    hist_df.to_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "model.save(\"model/vgg16/vgg_16.h5\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine Tuning\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height = 224 # Set the height of the picture\n",
    "img_width = 224 # Set the width of the picture\n",
    "\n",
    "# load model\n",
    "vgg16_model = tf.keras.applications.VGG16(input_shape=(img_height, img_width,3),\n",
    "                                          include_top=False, # Transfer learning\n",
    "                                          weights=\"imagenet\",\n",
    "                                          )  \n",
    "\n",
    "# Let's take a look to see how many layers are in the base model\n",
    "print(\"Number of layers in the base model: \", len(vgg16_model.layers))\n",
    "\n",
    "# Fine-tune from this layer onwards\n",
    "fine_tune_at = 15\n",
    "\n",
    "# Freeze all the layers before the `fine_tune_at` layer\n",
    "for layer in vgg16_model.layers[:fine_tune_at]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Make sure you have frozen the correct layers\n",
    "for i, layer in enumerate(vgg16_model.layers):\n",
    "    print(i, layer.name, layer.trainable)\n",
    "\n",
    "# Add input layers and output layers\n",
    "average_pooling_layer = tf.keras.layers.GlobalAveragePooling2D()(vgg16_model.output) # flatten\n",
    "prediction_layer = tf.keras.layers.Dense(units=4, activation=\"softmax\")(average_pooling_layer)\n",
    "fineture_model = tf.keras.models.Model(inputs=vgg16_model.input, \n",
    "                                     outputs=prediction_layer)\n",
    "\n",
    "# Compile the model         \n",
    "fineture_model.compile(loss=\"categorical_crossentropy\", \n",
    "                       optimizer = tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                       metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save checkpoints during training\n",
    "# follow value of vaildation scorce \n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint('model/vgg16/vgg_16_tf.h5', \n",
    "                             monitor= 'val_accuracy', \n",
    "                             mode= 'max', \n",
    "                             save_best_only = True, \n",
    "                             verbose= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training model\n",
    "# make sure you truely save checkpoint_path\n",
    "history_ft = fineture_model.fit(train_dataset,  \n",
    "                             epochs=25, \n",
    "                             validation_data=valid_dataset, \n",
    "                             callbacks=[checkpoint]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot graph \n",
    "plot_graph(history_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the history.history dict to a pandas DataFrame:     \n",
    "hist_df = pd.DataFrame(history_ft.history) \n",
    "hist_df.head()\n",
    "\n",
    "# save to csv: \n",
    "hist_csv_file = 'model/vgg16/history_vgg16_ft.csv'\n",
    "with open(hist_csv_file, mode='w') as f:\n",
    "    hist_df.to_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model after fine tuning \n",
    "fineture_model.save(\"model/vgg16/vgg_16_ft.h5\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
